Loading hyperparameters from: /home/soufiane/anaconda3/envs/envSB3/lib/python3.9/site-packages/rl_zoo3/hyperparams/td3.yml
Default hyperparameters for environment (ones being tuned will be overridden):
OrderedDict([('gamma', 0.9999),
             ('gradient_steps', 1),
             ('learning_starts', 10000),
             ('n_timesteps', 1000000.0),
             ('noise_std', 0.1),
             ('noise_type', 'normal'),
             ('normalize', False),
             ('policy', 'MlpPolicy'),
             ('train_freq', 1)])
Using 1 environments
Creating test environment
Applying normal noise with std 0.1
Using cpu device
Log path: logs/td3/Swimmer-v3_1
Logging to runs/Swimmer-v3__td3__3643959395__1677702698/Swimmer-v3/TD3_1
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | -7.92    |
| time/              |          |
|    episodes        | 4        |
|    fps             | 2218     |
|    time_elapsed    | 1        |
|    total_timesteps | 4000     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | -4.59    |
| time/              |          |
|    episodes        | 8        |
|    fps             | 2219     |
|    time_elapsed    | 3        |
|    total_timesteps | 8000     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 0.974    |
| time/              |          |
|    episodes        | 12       |
|    fps             | 458      |
|    time_elapsed    | 26       |
|    total_timesteps | 12000    |
| train/             |          |
|    actor_loss      | -4.1     |
|    critic_loss     | 0.116    |
|    learning_rate   | 0.001    |
|    n_updates       | 1999     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 6.58     |
| time/              |          |
|    episodes        | 16       |
|    fps             | 178      |
|    time_elapsed    | 89       |
|    total_timesteps | 16000    |
| train/             |          |
|    actor_loss      | -10      |
|    critic_loss     | 0.125    |
|    learning_rate   | 0.001    |
|    n_updates       | 5999     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 10.1     |
| time/              |          |
|    episodes        | 20       |
|    fps             | 125      |
|    time_elapsed    | 158      |
|    total_timesteps | 20000    |
| train/             |          |
|    actor_loss      | -12      |
|    critic_loss     | 0.14     |
|    learning_rate   | 0.001    |
|    n_updates       | 9999     |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 11.4     |
| time/              |          |
|    episodes        | 24       |
|    fps             | 106      |
|    time_elapsed    | 225      |
|    total_timesteps | 24000    |
| train/             |          |
|    actor_loss      | -16.9    |
|    critic_loss     | 0.0467   |
|    learning_rate   | 0.001    |
|    n_updates       | 13999    |
---------------------------------
Eval num_timesteps=25000, episode_reward=16.02 +/- 20.73
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 16       |
| time/              |          |
|    total_timesteps | 25000    |
| train/             |          |
|    actor_loss      | -16.5    |
|    critic_loss     | 0.0513   |
|    learning_rate   | 0.001    |
|    n_updates       | 14999    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 12.8     |
| time/              |          |
|    episodes        | 28       |
|    fps             | 93       |
|    time_elapsed    | 299      |
|    total_timesteps | 28000    |
| train/             |          |
|    actor_loss      | -21.1    |
|    critic_loss     | 0.069    |
|    learning_rate   | 0.001    |
|    n_updates       | 17999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 14.3     |
| time/              |          |
|    episodes        | 32       |
|    fps             | 89       |
|    time_elapsed    | 355      |
|    total_timesteps | 32000    |
| train/             |          |
|    actor_loss      | -24.2    |
|    critic_loss     | 0.0642   |
|    learning_rate   | 0.001    |
|    n_updates       | 21999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 15.6     |
| time/              |          |
|    episodes        | 36       |
|    fps             | 87       |
|    time_elapsed    | 409      |
|    total_timesteps | 36000    |
| train/             |          |
|    actor_loss      | -26.4    |
|    critic_loss     | 0.0765   |
|    learning_rate   | 0.001    |
|    n_updates       | 25999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 16.3     |
| time/              |          |
|    episodes        | 40       |
|    fps             | 88       |
|    time_elapsed    | 450      |
|    total_timesteps | 40000    |
| train/             |          |
|    actor_loss      | -28.7    |
|    critic_loss     | 0.131    |
|    learning_rate   | 0.001    |
|    n_updates       | 29999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 18       |
| time/              |          |
|    episodes        | 44       |
|    fps             | 88       |
|    time_elapsed    | 497      |
|    total_timesteps | 44000    |
| train/             |          |
|    actor_loss      | -31.9    |
|    critic_loss     | 0.0848   |
|    learning_rate   | 0.001    |
|    n_updates       | 33999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 19.3     |
| time/              |          |
|    episodes        | 48       |
|    fps             | 85       |
|    time_elapsed    | 562      |
|    total_timesteps | 48000    |
| train/             |          |
|    actor_loss      | -34      |
|    critic_loss     | 0.127    |
|    learning_rate   | 0.001    |
|    n_updates       | 37999    |
---------------------------------
Eval num_timesteps=50000, episode_reward=-8.31 +/- 5.65
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | -8.31    |
| time/              |          |
|    total_timesteps | 50000    |
| train/             |          |
|    actor_loss      | -37.1    |
|    critic_loss     | 0.114    |
|    learning_rate   | 0.001    |
|    n_updates       | 39999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 19       |
| time/              |          |
|    episodes        | 52       |
|    fps             | 84       |
|    time_elapsed    | 618      |
|    total_timesteps | 52000    |
| train/             |          |
|    actor_loss      | -38      |
|    critic_loss     | 0.0958   |
|    learning_rate   | 0.001    |
|    n_updates       | 41999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 18.8     |
| time/              |          |
|    episodes        | 56       |
|    fps             | 83       |
|    time_elapsed    | 671      |
|    total_timesteps | 56000    |
| train/             |          |
|    actor_loss      | -40.6    |
|    critic_loss     | 0.114    |
|    learning_rate   | 0.001    |
|    n_updates       | 45999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 18.9     |
| time/              |          |
|    episodes        | 60       |
|    fps             | 83       |
|    time_elapsed    | 719      |
|    total_timesteps | 60000    |
| train/             |          |
|    actor_loss      | -43.5    |
|    critic_loss     | 0.0682   |
|    learning_rate   | 0.001    |
|    n_updates       | 49999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 20.3     |
| time/              |          |
|    episodes        | 64       |
|    fps             | 83       |
|    time_elapsed    | 765      |
|    total_timesteps | 64000    |
| train/             |          |
|    actor_loss      | -45      |
|    critic_loss     | 0.0555   |
|    learning_rate   | 0.001    |
|    n_updates       | 53999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 21.8     |
| time/              |          |
|    episodes        | 68       |
|    fps             | 83       |
|    time_elapsed    | 816      |
|    total_timesteps | 68000    |
| train/             |          |
|    actor_loss      | -46.2    |
|    critic_loss     | 0.0728   |
|    learning_rate   | 0.001    |
|    n_updates       | 57999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 21.8     |
| time/              |          |
|    episodes        | 72       |
|    fps             | 82       |
|    time_elapsed    | 873      |
|    total_timesteps | 72000    |
| train/             |          |
|    actor_loss      | -47.8    |
|    critic_loss     | 0.0651   |
|    learning_rate   | 0.001    |
|    n_updates       | 61999    |
---------------------------------
Eval num_timesteps=75000, episode_reward=81.15 +/- 29.59
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 81.2     |
| time/              |          |
|    total_timesteps | 75000    |
| train/             |          |
|    actor_loss      | -50.2    |
|    critic_loss     | 0.0737   |
|    learning_rate   | 0.001    |
|    n_updates       | 64999    |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 23.6     |
| time/              |          |
|    episodes        | 76       |
|    fps             | 82       |
|    time_elapsed    | 921      |
|    total_timesteps | 76000    |
| train/             |          |
|    actor_loss      | -48.9    |
|    critic_loss     | 0.0798   |
|    learning_rate   | 0.001    |
|    n_updates       | 65999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 23.3     |
| time/              |          |
|    episodes        | 80       |
|    fps             | 82       |
|    time_elapsed    | 967      |
|    total_timesteps | 80000    |
| train/             |          |
|    actor_loss      | -50.4    |
|    critic_loss     | 0.149    |
|    learning_rate   | 0.001    |
|    n_updates       | 69999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 22.9     |
| time/              |          |
|    episodes        | 84       |
|    fps             | 82       |
|    time_elapsed    | 1021     |
|    total_timesteps | 84000    |
| train/             |          |
|    actor_loss      | -53.6    |
|    critic_loss     | 0.0692   |
|    learning_rate   | 0.001    |
|    n_updates       | 73999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 22.4     |
| time/              |          |
|    episodes        | 88       |
|    fps             | 82       |
|    time_elapsed    | 1069     |
|    total_timesteps | 88000    |
| train/             |          |
|    actor_loss      | -54.9    |
|    critic_loss     | 0.0814   |
|    learning_rate   | 0.001    |
|    n_updates       | 77999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 22.4     |
| time/              |          |
|    episodes        | 92       |
|    fps             | 81       |
|    time_elapsed    | 1122     |
|    total_timesteps | 92000    |
| train/             |          |
|    actor_loss      | -58.3    |
|    critic_loss     | 0.0611   |
|    learning_rate   | 0.001    |
|    n_updates       | 81999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 21.9     |
| time/              |          |
|    episodes        | 96       |
|    fps             | 81       |
|    time_elapsed    | 1180     |
|    total_timesteps | 96000    |
| train/             |          |
|    actor_loss      | -62.1    |
|    critic_loss     | 0.056    |
|    learning_rate   | 0.001    |
|    n_updates       | 85999    |
---------------------------------
Eval num_timesteps=100000, episode_reward=24.20 +/- 8.59
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 24.2     |
| time/              |          |
|    total_timesteps | 100000   |
| train/             |          |
|    actor_loss      | -62.3    |
|    critic_loss     | 0.119    |
|    learning_rate   | 0.001    |
|    n_updates       | 89999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 21.6     |
| time/              |          |
|    episodes        | 100      |
|    fps             | 80       |
|    time_elapsed    | 1240     |
|    total_timesteps | 100000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 22.5     |
| time/              |          |
|    episodes        | 104      |
|    fps             | 79       |
|    time_elapsed    | 1306     |
|    total_timesteps | 104000   |
| train/             |          |
|    actor_loss      | -65.1    |
|    critic_loss     | 0.0627   |
|    learning_rate   | 0.001    |
|    n_updates       | 93999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 23       |
| time/              |          |
|    episodes        | 108      |
|    fps             | 79       |
|    time_elapsed    | 1361     |
|    total_timesteps | 108000   |
| train/             |          |
|    actor_loss      | -65.1    |
|    critic_loss     | 0.0548   |
|    learning_rate   | 0.001    |
|    n_updates       | 97999    |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 23.9     |
| time/              |          |
|    episodes        | 112      |
|    fps             | 79       |
|    time_elapsed    | 1413     |
|    total_timesteps | 112000   |
| train/             |          |
|    actor_loss      | -69.1    |
|    critic_loss     | 0.0706   |
|    learning_rate   | 0.001    |
|    n_updates       | 101999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 25       |
| time/              |          |
|    episodes        | 116      |
|    fps             | 79       |
|    time_elapsed    | 1467     |
|    total_timesteps | 116000   |
| train/             |          |
|    actor_loss      | -67.3    |
|    critic_loss     | 0.132    |
|    learning_rate   | 0.001    |
|    n_updates       | 105999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 24.7     |
| time/              |          |
|    episodes        | 120      |
|    fps             | 78       |
|    time_elapsed    | 1530     |
|    total_timesteps | 120000   |
| train/             |          |
|    actor_loss      | -70.5    |
|    critic_loss     | 0.0613   |
|    learning_rate   | 0.001    |
|    n_updates       | 109999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 25.4     |
| time/              |          |
|    episodes        | 124      |
|    fps             | 77       |
|    time_elapsed    | 1593     |
|    total_timesteps | 124000   |
| train/             |          |
|    actor_loss      | -74.8    |
|    critic_loss     | 0.0953   |
|    learning_rate   | 0.001    |
|    n_updates       | 113999   |
---------------------------------
Eval num_timesteps=125000, episode_reward=23.68 +/- 0.91
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 23.7     |
| time/              |          |
|    total_timesteps | 125000   |
| train/             |          |
|    actor_loss      | -74.6    |
|    critic_loss     | 0.06     |
|    learning_rate   | 0.001    |
|    n_updates       | 114999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 25.8     |
| time/              |          |
|    episodes        | 128      |
|    fps             | 77       |
|    time_elapsed    | 1656     |
|    total_timesteps | 128000   |
| train/             |          |
|    actor_loss      | -78.7    |
|    critic_loss     | 0.0955   |
|    learning_rate   | 0.001    |
|    n_updates       | 117999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 28.7     |
| time/              |          |
|    episodes        | 132      |
|    fps             | 76       |
|    time_elapsed    | 1718     |
|    total_timesteps | 132000   |
| train/             |          |
|    actor_loss      | -80.6    |
|    critic_loss     | 0.11     |
|    learning_rate   | 0.001    |
|    n_updates       | 121999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 30       |
| time/              |          |
|    episodes        | 136      |
|    fps             | 75       |
|    time_elapsed    | 1794     |
|    total_timesteps | 136000   |
| train/             |          |
|    actor_loss      | -85      |
|    critic_loss     | 0.0546   |
|    learning_rate   | 0.001    |
|    n_updates       | 125999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 33.5     |
| time/              |          |
|    episodes        | 140      |
|    fps             | 75       |
|    time_elapsed    | 1864     |
|    total_timesteps | 140000   |
| train/             |          |
|    actor_loss      | -83.1    |
|    critic_loss     | 0.0658   |
|    learning_rate   | 0.001    |
|    n_updates       | 129999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 36.8     |
| time/              |          |
|    episodes        | 144      |
|    fps             | 73       |
|    time_elapsed    | 1947     |
|    total_timesteps | 144000   |
| train/             |          |
|    actor_loss      | -85.2    |
|    critic_loss     | 0.0938   |
|    learning_rate   | 0.001    |
|    n_updates       | 133999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 43.4     |
| time/              |          |
|    episodes        | 148      |
|    fps             | 73       |
|    time_elapsed    | 2012     |
|    total_timesteps | 148000   |
| train/             |          |
|    actor_loss      | -88.1    |
|    critic_loss     | 0.0663   |
|    learning_rate   | 0.001    |
|    n_updates       | 137999   |
---------------------------------
Eval num_timesteps=150000, episode_reward=175.56 +/- 20.75
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 176      |
| time/              |          |
|    total_timesteps | 150000   |
| train/             |          |
|    actor_loss      | -87.7    |
|    critic_loss     | 0.0696   |
|    learning_rate   | 0.001    |
|    n_updates       | 139999   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 51.7     |
| time/              |          |
|    episodes        | 152      |
|    fps             | 73       |
|    time_elapsed    | 2080     |
|    total_timesteps | 152000   |
| train/             |          |
|    actor_loss      | -88.1    |
|    critic_loss     | 0.0973   |
|    learning_rate   | 0.001    |
|    n_updates       | 141999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 63.3     |
| time/              |          |
|    episodes        | 156      |
|    fps             | 72       |
|    time_elapsed    | 2147     |
|    total_timesteps | 156000   |
| train/             |          |
|    actor_loss      | -92.2    |
|    critic_loss     | 0.161    |
|    learning_rate   | 0.001    |
|    n_updates       | 145999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 75.7     |
| time/              |          |
|    episodes        | 160      |
|    fps             | 72       |
|    time_elapsed    | 2214     |
|    total_timesteps | 160000   |
| train/             |          |
|    actor_loss      | -93.7    |
|    critic_loss     | 0.163    |
|    learning_rate   | 0.001    |
|    n_updates       | 149999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 87.4     |
| time/              |          |
|    episodes        | 164      |
|    fps             | 71       |
|    time_elapsed    | 2295     |
|    total_timesteps | 164000   |
| train/             |          |
|    actor_loss      | -92.5    |
|    critic_loss     | 0.0959   |
|    learning_rate   | 0.001    |
|    n_updates       | 153999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 99.2     |
| time/              |          |
|    episodes        | 168      |
|    fps             | 71       |
|    time_elapsed    | 2353     |
|    total_timesteps | 168000   |
| train/             |          |
|    actor_loss      | -95.6    |
|    critic_loss     | 0.258    |
|    learning_rate   | 0.001    |
|    n_updates       | 157999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 112      |
| time/              |          |
|    episodes        | 172      |
|    fps             | 70       |
|    time_elapsed    | 2438     |
|    total_timesteps | 172000   |
| train/             |          |
|    actor_loss      | -104     |
|    critic_loss     | 0.127    |
|    learning_rate   | 0.001    |
|    n_updates       | 161999   |
---------------------------------
Eval num_timesteps=175000, episode_reward=343.17 +/- 3.21
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 343      |
| time/              |          |
|    total_timesteps | 175000   |
| train/             |          |
|    actor_loss      | -104     |
|    critic_loss     | 0.147    |
|    learning_rate   | 0.001    |
|    n_updates       | 164999   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 123      |
| time/              |          |
|    episodes        | 176      |
|    fps             | 69       |
|    time_elapsed    | 2542     |
|    total_timesteps | 176000   |
| train/             |          |
|    actor_loss      | -103     |
|    critic_loss     | 0.0827   |
|    learning_rate   | 0.001    |
|    n_updates       | 165999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 136      |
| time/              |          |
|    episodes        | 180      |
|    fps             | 68       |
|    time_elapsed    | 2636     |
|    total_timesteps | 180000   |
| train/             |          |
|    actor_loss      | -106     |
|    critic_loss     | 0.145    |
|    learning_rate   | 0.001    |
|    n_updates       | 169999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 149      |
| time/              |          |
|    episodes        | 184      |
|    fps             | 68       |
|    time_elapsed    | 2693     |
|    total_timesteps | 184000   |
| train/             |          |
|    actor_loss      | -112     |
|    critic_loss     | 0.08     |
|    learning_rate   | 0.001    |
|    n_updates       | 173999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 162      |
| time/              |          |
|    episodes        | 188      |
|    fps             | 68       |
|    time_elapsed    | 2758     |
|    total_timesteps | 188000   |
| train/             |          |
|    actor_loss      | -109     |
|    critic_loss     | 0.16     |
|    learning_rate   | 0.001    |
|    n_updates       | 177999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 174      |
| time/              |          |
|    episodes        | 192      |
|    fps             | 67       |
|    time_elapsed    | 2826     |
|    total_timesteps | 192000   |
| train/             |          |
|    actor_loss      | -116     |
|    critic_loss     | 0.149    |
|    learning_rate   | 0.001    |
|    n_updates       | 181999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 187      |
| time/              |          |
|    episodes        | 196      |
|    fps             | 68       |
|    time_elapsed    | 2881     |
|    total_timesteps | 196000   |
| train/             |          |
|    actor_loss      | -119     |
|    critic_loss     | 0.127    |
|    learning_rate   | 0.001    |
|    n_updates       | 185999   |
---------------------------------
Eval num_timesteps=200000, episode_reward=352.58 +/- 1.47
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 353      |
| time/              |          |
|    total_timesteps | 200000   |
| train/             |          |
|    actor_loss      | -125     |
|    critic_loss     | 0.114    |
|    learning_rate   | 0.001    |
|    n_updates       | 189999   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 200      |
| time/              |          |
|    episodes        | 200      |
|    fps             | 67       |
|    time_elapsed    | 2949     |
|    total_timesteps | 200000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 213      |
| time/              |          |
|    episodes        | 204      |
|    fps             | 67       |
|    time_elapsed    | 3026     |
|    total_timesteps | 204000   |
| train/             |          |
|    actor_loss      | -122     |
|    critic_loss     | 0.106    |
|    learning_rate   | 0.001    |
|    n_updates       | 193999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 226      |
| time/              |          |
|    episodes        | 208      |
|    fps             | 67       |
|    time_elapsed    | 3092     |
|    total_timesteps | 208000   |
| train/             |          |
|    actor_loss      | -127     |
|    critic_loss     | 0.109    |
|    learning_rate   | 0.001    |
|    n_updates       | 197999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 239      |
| time/              |          |
|    episodes        | 212      |
|    fps             | 67       |
|    time_elapsed    | 3164     |
|    total_timesteps | 212000   |
| train/             |          |
|    actor_loss      | -128     |
|    critic_loss     | 0.126    |
|    learning_rate   | 0.001    |
|    n_updates       | 201999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 250      |
| time/              |          |
|    episodes        | 216      |
|    fps             | 67       |
|    time_elapsed    | 3217     |
|    total_timesteps | 216000   |
| train/             |          |
|    actor_loss      | -131     |
|    critic_loss     | 0.113    |
|    learning_rate   | 0.001    |
|    n_updates       | 205999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 263      |
| time/              |          |
|    episodes        | 220      |
|    fps             | 67       |
|    time_elapsed    | 3271     |
|    total_timesteps | 220000   |
| train/             |          |
|    actor_loss      | -135     |
|    critic_loss     | 0.0757   |
|    learning_rate   | 0.001    |
|    n_updates       | 209999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 276      |
| time/              |          |
|    episodes        | 224      |
|    fps             | 67       |
|    time_elapsed    | 3333     |
|    total_timesteps | 224000   |
| train/             |          |
|    actor_loss      | -140     |
|    critic_loss     | 0.0892   |
|    learning_rate   | 0.001    |
|    n_updates       | 213999   |
---------------------------------
Eval num_timesteps=225000, episode_reward=356.57 +/- 2.21
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 357      |
| time/              |          |
|    total_timesteps | 225000   |
| train/             |          |
|    actor_loss      | -142     |
|    critic_loss     | 0.0929   |
|    learning_rate   | 0.001    |
|    n_updates       | 214999   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 288      |
| time/              |          |
|    episodes        | 228      |
|    fps             | 67       |
|    time_elapsed    | 3401     |
|    total_timesteps | 228000   |
| train/             |          |
|    actor_loss      | -144     |
|    critic_loss     | 0.104    |
|    learning_rate   | 0.001    |
|    n_updates       | 217999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 298      |
| time/              |          |
|    episodes        | 232      |
|    fps             | 66       |
|    time_elapsed    | 3463     |
|    total_timesteps | 232000   |
| train/             |          |
|    actor_loss      | -145     |
|    critic_loss     | 0.082    |
|    learning_rate   | 0.001    |
|    n_updates       | 221999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 310      |
| time/              |          |
|    episodes        | 236      |
|    fps             | 67       |
|    time_elapsed    | 3522     |
|    total_timesteps | 236000   |
| train/             |          |
|    actor_loss      | -143     |
|    critic_loss     | 0.0669   |
|    learning_rate   | 0.001    |
|    n_updates       | 225999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 319      |
| time/              |          |
|    episodes        | 240      |
|    fps             | 66       |
|    time_elapsed    | 3584     |
|    total_timesteps | 240000   |
| train/             |          |
|    actor_loss      | -148     |
|    critic_loss     | 0.105    |
|    learning_rate   | 0.001    |
|    n_updates       | 229999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 328      |
| time/              |          |
|    episodes        | 244      |
|    fps             | 66       |
|    time_elapsed    | 3652     |
|    total_timesteps | 244000   |
| train/             |          |
|    actor_loss      | -155     |
|    critic_loss     | 0.109    |
|    learning_rate   | 0.001    |
|    n_updates       | 233999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 334      |
| time/              |          |
|    episodes        | 248      |
|    fps             | 66       |
|    time_elapsed    | 3738     |
|    total_timesteps | 248000   |
| train/             |          |
|    actor_loss      | -158     |
|    critic_loss     | 0.169    |
|    learning_rate   | 0.001    |
|    n_updates       | 237999   |
---------------------------------
Eval num_timesteps=250000, episode_reward=355.74 +/- 2.69
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 356      |
| time/              |          |
|    total_timesteps | 250000   |
| train/             |          |
|    actor_loss      | -159     |
|    critic_loss     | 0.0753   |
|    learning_rate   | 0.001    |
|    n_updates       | 239999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 339      |
| time/              |          |
|    episodes        | 252      |
|    fps             | 65       |
|    time_elapsed    | 3823     |
|    total_timesteps | 252000   |
| train/             |          |
|    actor_loss      | -161     |
|    critic_loss     | 0.0791   |
|    learning_rate   | 0.001    |
|    n_updates       | 241999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 340      |
| time/              |          |
|    episodes        | 256      |
|    fps             | 65       |
|    time_elapsed    | 3878     |
|    total_timesteps | 256000   |
| train/             |          |
|    actor_loss      | -165     |
|    critic_loss     | 0.118    |
|    learning_rate   | 0.001    |
|    n_updates       | 245999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 341      |
| time/              |          |
|    episodes        | 260      |
|    fps             | 65       |
|    time_elapsed    | 3945     |
|    total_timesteps | 260000   |
| train/             |          |
|    actor_loss      | -166     |
|    critic_loss     | 0.094    |
|    learning_rate   | 0.001    |
|    n_updates       | 249999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 341      |
| time/              |          |
|    episodes        | 264      |
|    fps             | 65       |
|    time_elapsed    | 4026     |
|    total_timesteps | 264000   |
| train/             |          |
|    actor_loss      | -169     |
|    critic_loss     | 0.0885   |
|    learning_rate   | 0.001    |
|    n_updates       | 253999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 341      |
| time/              |          |
|    episodes        | 268      |
|    fps             | 65       |
|    time_elapsed    | 4098     |
|    total_timesteps | 268000   |
| train/             |          |
|    actor_loss      | -173     |
|    critic_loss     | 0.296    |
|    learning_rate   | 0.001    |
|    n_updates       | 257999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 342      |
| time/              |          |
|    episodes        | 272      |
|    fps             | 65       |
|    time_elapsed    | 4148     |
|    total_timesteps | 272000   |
| train/             |          |
|    actor_loss      | -176     |
|    critic_loss     | 0.146    |
|    learning_rate   | 0.001    |
|    n_updates       | 261999   |
---------------------------------
Eval num_timesteps=275000, episode_reward=358.17 +/- 2.35
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 358      |
| time/              |          |
|    total_timesteps | 275000   |
| train/             |          |
|    actor_loss      | -181     |
|    critic_loss     | 0.133    |
|    learning_rate   | 0.001    |
|    n_updates       | 264999   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 342      |
| time/              |          |
|    episodes        | 276      |
|    fps             | 65       |
|    time_elapsed    | 4206     |
|    total_timesteps | 276000   |
| train/             |          |
|    actor_loss      | -177     |
|    critic_loss     | 0.0798   |
|    learning_rate   | 0.001    |
|    n_updates       | 265999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 343      |
| time/              |          |
|    episodes        | 280      |
|    fps             | 65       |
|    time_elapsed    | 4258     |
|    total_timesteps | 280000   |
| train/             |          |
|    actor_loss      | -181     |
|    critic_loss     | 0.115    |
|    learning_rate   | 0.001    |
|    n_updates       | 269999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 343      |
| time/              |          |
|    episodes        | 284      |
|    fps             | 65       |
|    time_elapsed    | 4321     |
|    total_timesteps | 284000   |
| train/             |          |
|    actor_loss      | -186     |
|    critic_loss     | 0.122    |
|    learning_rate   | 0.001    |
|    n_updates       | 273999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 343      |
| time/              |          |
|    episodes        | 288      |
|    fps             | 65       |
|    time_elapsed    | 4382     |
|    total_timesteps | 288000   |
| train/             |          |
|    actor_loss      | -188     |
|    critic_loss     | 0.113    |
|    learning_rate   | 0.001    |
|    n_updates       | 277999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 343      |
| time/              |          |
|    episodes        | 292      |
|    fps             | 65       |
|    time_elapsed    | 4444     |
|    total_timesteps | 292000   |
| train/             |          |
|    actor_loss      | -191     |
|    critic_loss     | 0.096    |
|    learning_rate   | 0.001    |
|    n_updates       | 281999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 344      |
| time/              |          |
|    episodes        | 296      |
|    fps             | 65       |
|    time_elapsed    | 4517     |
|    total_timesteps | 296000   |
| train/             |          |
|    actor_loss      | -200     |
|    critic_loss     | 0.251    |
|    learning_rate   | 0.001    |
|    n_updates       | 285999   |
---------------------------------
Eval num_timesteps=300000, episode_reward=350.10 +/- 0.83
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 350      |
| time/              |          |
|    total_timesteps | 300000   |
| train/             |          |
|    actor_loss      | -199     |
|    critic_loss     | 0.109    |
|    learning_rate   | 0.001    |
|    n_updates       | 289999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 344      |
| time/              |          |
|    episodes        | 300      |
|    fps             | 65       |
|    time_elapsed    | 4582     |
|    total_timesteps | 300000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 344      |
| time/              |          |
|    episodes        | 304      |
|    fps             | 65       |
|    time_elapsed    | 4644     |
|    total_timesteps | 304000   |
| train/             |          |
|    actor_loss      | -200     |
|    critic_loss     | 0.258    |
|    learning_rate   | 0.001    |
|    n_updates       | 293999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 344      |
| time/              |          |
|    episodes        | 308      |
|    fps             | 65       |
|    time_elapsed    | 4714     |
|    total_timesteps | 308000   |
| train/             |          |
|    actor_loss      | -201     |
|    critic_loss     | 0.0707   |
|    learning_rate   | 0.001    |
|    n_updates       | 297999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 344      |
| time/              |          |
|    episodes        | 312      |
|    fps             | 65       |
|    time_elapsed    | 4777     |
|    total_timesteps | 312000   |
| train/             |          |
|    actor_loss      | -206     |
|    critic_loss     | 0.145    |
|    learning_rate   | 0.001    |
|    n_updates       | 301999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 316      |
|    fps             | 65       |
|    time_elapsed    | 4835     |
|    total_timesteps | 316000   |
| train/             |          |
|    actor_loss      | -210     |
|    critic_loss     | 0.236    |
|    learning_rate   | 0.001    |
|    n_updates       | 305999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 320      |
|    fps             | 65       |
|    time_elapsed    | 4894     |
|    total_timesteps | 320000   |
| train/             |          |
|    actor_loss      | -216     |
|    critic_loss     | 0.121    |
|    learning_rate   | 0.001    |
|    n_updates       | 309999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 324      |
|    fps             | 65       |
|    time_elapsed    | 4955     |
|    total_timesteps | 324000   |
| train/             |          |
|    actor_loss      | -218     |
|    critic_loss     | 0.148    |
|    learning_rate   | 0.001    |
|    n_updates       | 313999   |
---------------------------------
Eval num_timesteps=325000, episode_reward=353.82 +/- 0.96
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 354      |
| time/              |          |
|    total_timesteps | 325000   |
| train/             |          |
|    actor_loss      | -220     |
|    critic_loss     | 0.137    |
|    learning_rate   | 0.001    |
|    n_updates       | 314999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 328      |
|    fps             | 65       |
|    time_elapsed    | 5018     |
|    total_timesteps | 328000   |
| train/             |          |
|    actor_loss      | -221     |
|    critic_loss     | 0.139    |
|    learning_rate   | 0.001    |
|    n_updates       | 317999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 332      |
|    fps             | 65       |
|    time_elapsed    | 5079     |
|    total_timesteps | 332000   |
| train/             |          |
|    actor_loss      | -224     |
|    critic_loss     | 0.192    |
|    learning_rate   | 0.001    |
|    n_updates       | 321999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 336      |
|    fps             | 65       |
|    time_elapsed    | 5140     |
|    total_timesteps | 336000   |
| train/             |          |
|    actor_loss      | -225     |
|    critic_loss     | 0.139    |
|    learning_rate   | 0.001    |
|    n_updates       | 325999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 340      |
|    fps             | 65       |
|    time_elapsed    | 5200     |
|    total_timesteps | 340000   |
| train/             |          |
|    actor_loss      | -229     |
|    critic_loss     | 0.132    |
|    learning_rate   | 0.001    |
|    n_updates       | 329999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 344      |
|    fps             | 65       |
|    time_elapsed    | 5260     |
|    total_timesteps | 344000   |
| train/             |          |
|    actor_loss      | -233     |
|    critic_loss     | 0.112    |
|    learning_rate   | 0.001    |
|    n_updates       | 333999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 348      |
|    fps             | 65       |
|    time_elapsed    | 5320     |
|    total_timesteps | 348000   |
| train/             |          |
|    actor_loss      | -237     |
|    critic_loss     | 0.0829   |
|    learning_rate   | 0.001    |
|    n_updates       | 337999   |
---------------------------------
Eval num_timesteps=350000, episode_reward=355.02 +/- 2.04
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 355      |
| time/              |          |
|    total_timesteps | 350000   |
| train/             |          |
|    actor_loss      | -239     |
|    critic_loss     | 0.16     |
|    learning_rate   | 0.001    |
|    n_updates       | 339999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 352      |
|    fps             | 65       |
|    time_elapsed    | 5383     |
|    total_timesteps | 352000   |
| train/             |          |
|    actor_loss      | -240     |
|    critic_loss     | 0.326    |
|    learning_rate   | 0.001    |
|    n_updates       | 341999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 356      |
|    fps             | 65       |
|    time_elapsed    | 5443     |
|    total_timesteps | 356000   |
| train/             |          |
|    actor_loss      | -244     |
|    critic_loss     | 0.122    |
|    learning_rate   | 0.001    |
|    n_updates       | 345999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 360      |
|    fps             | 65       |
|    time_elapsed    | 5506     |
|    total_timesteps | 360000   |
| train/             |          |
|    actor_loss      | -244     |
|    critic_loss     | 0.153    |
|    learning_rate   | 0.001    |
|    n_updates       | 349999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 364      |
|    fps             | 65       |
|    time_elapsed    | 5566     |
|    total_timesteps | 364000   |
| train/             |          |
|    actor_loss      | -250     |
|    critic_loss     | 0.263    |
|    learning_rate   | 0.001    |
|    n_updates       | 353999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 368      |
|    fps             | 65       |
|    time_elapsed    | 5626     |
|    total_timesteps | 368000   |
| train/             |          |
|    actor_loss      | -254     |
|    critic_loss     | 0.0889   |
|    learning_rate   | 0.001    |
|    n_updates       | 357999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 372      |
|    fps             | 65       |
|    time_elapsed    | 5686     |
|    total_timesteps | 372000   |
| train/             |          |
|    actor_loss      | -257     |
|    critic_loss     | 0.262    |
|    learning_rate   | 0.001    |
|    n_updates       | 361999   |
---------------------------------
Eval num_timesteps=375000, episode_reward=356.89 +/- 0.41
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 357      |
| time/              |          |
|    total_timesteps | 375000   |
| train/             |          |
|    actor_loss      | -257     |
|    critic_loss     | 0.078    |
|    learning_rate   | 0.001    |
|    n_updates       | 364999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 376      |
|    fps             | 65       |
|    time_elapsed    | 5750     |
|    total_timesteps | 376000   |
| train/             |          |
|    actor_loss      | -255     |
|    critic_loss     | 0.144    |
|    learning_rate   | 0.001    |
|    n_updates       | 365999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 380      |
|    fps             | 65       |
|    time_elapsed    | 5810     |
|    total_timesteps | 380000   |
| train/             |          |
|    actor_loss      | -261     |
|    critic_loss     | 0.164    |
|    learning_rate   | 0.001    |
|    n_updates       | 369999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 384      |
|    fps             | 65       |
|    time_elapsed    | 5871     |
|    total_timesteps | 384000   |
| train/             |          |
|    actor_loss      | -266     |
|    critic_loss     | 0.188    |
|    learning_rate   | 0.001    |
|    n_updates       | 373999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 388      |
|    fps             | 65       |
|    time_elapsed    | 5932     |
|    total_timesteps | 388000   |
| train/             |          |
|    actor_loss      | -269     |
|    critic_loss     | 0.0587   |
|    learning_rate   | 0.001    |
|    n_updates       | 377999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 392      |
|    fps             | 65       |
|    time_elapsed    | 5993     |
|    total_timesteps | 392000   |
| train/             |          |
|    actor_loss      | -270     |
|    critic_loss     | 0.222    |
|    learning_rate   | 0.001    |
|    n_updates       | 381999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 396      |
|    fps             | 65       |
|    time_elapsed    | 6054     |
|    total_timesteps | 396000   |
| train/             |          |
|    actor_loss      | -275     |
|    critic_loss     | 0.101    |
|    learning_rate   | 0.001    |
|    n_updates       | 385999   |
---------------------------------
Eval num_timesteps=400000, episode_reward=360.88 +/- 1.51
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 361      |
| time/              |          |
|    total_timesteps | 400000   |
| train/             |          |
|    actor_loss      | -277     |
|    critic_loss     | 0.298    |
|    learning_rate   | 0.001    |
|    n_updates       | 389999   |
---------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 400      |
|    fps             | 65       |
|    time_elapsed    | 6118     |
|    total_timesteps | 400000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 404      |
|    fps             | 65       |
|    time_elapsed    | 6178     |
|    total_timesteps | 404000   |
| train/             |          |
|    actor_loss      | -283     |
|    critic_loss     | 0.0926   |
|    learning_rate   | 0.001    |
|    n_updates       | 393999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 408      |
|    fps             | 65       |
|    time_elapsed    | 6244     |
|    total_timesteps | 408000   |
| train/             |          |
|    actor_loss      | -282     |
|    critic_loss     | 0.0889   |
|    learning_rate   | 0.001    |
|    n_updates       | 397999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 412      |
|    fps             | 65       |
|    time_elapsed    | 6307     |
|    total_timesteps | 412000   |
| train/             |          |
|    actor_loss      | -289     |
|    critic_loss     | 0.127    |
|    learning_rate   | 0.001    |
|    n_updates       | 401999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 416      |
|    fps             | 65       |
|    time_elapsed    | 6369     |
|    total_timesteps | 416000   |
| train/             |          |
|    actor_loss      | -287     |
|    critic_loss     | 0.159    |
|    learning_rate   | 0.001    |
|    n_updates       | 405999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 420      |
|    fps             | 65       |
|    time_elapsed    | 6430     |
|    total_timesteps | 420000   |
| train/             |          |
|    actor_loss      | -292     |
|    critic_loss     | 0.12     |
|    learning_rate   | 0.001    |
|    n_updates       | 409999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 424      |
|    fps             | 65       |
|    time_elapsed    | 6491     |
|    total_timesteps | 424000   |
| train/             |          |
|    actor_loss      | -297     |
|    critic_loss     | 0.0776   |
|    learning_rate   | 0.001    |
|    n_updates       | 413999   |
---------------------------------
Eval num_timesteps=425000, episode_reward=351.45 +/- 3.15
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 351      |
| time/              |          |
|    total_timesteps | 425000   |
| train/             |          |
|    actor_loss      | -299     |
|    critic_loss     | 0.107    |
|    learning_rate   | 0.001    |
|    n_updates       | 414999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 428      |
|    fps             | 65       |
|    time_elapsed    | 6556     |
|    total_timesteps | 428000   |
| train/             |          |
|    actor_loss      | -300     |
|    critic_loss     | 0.0758   |
|    learning_rate   | 0.001    |
|    n_updates       | 417999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 432      |
|    fps             | 65       |
|    time_elapsed    | 6618     |
|    total_timesteps | 432000   |
| train/             |          |
|    actor_loss      | -302     |
|    critic_loss     | 0.292    |
|    learning_rate   | 0.001    |
|    n_updates       | 421999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 436      |
|    fps             | 65       |
|    time_elapsed    | 6694     |
|    total_timesteps | 436000   |
| train/             |          |
|    actor_loss      | -302     |
|    critic_loss     | 0.111    |
|    learning_rate   | 0.001    |
|    n_updates       | 425999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 440      |
|    fps             | 65       |
|    time_elapsed    | 6759     |
|    total_timesteps | 440000   |
| train/             |          |
|    actor_loss      | -309     |
|    critic_loss     | 0.132    |
|    learning_rate   | 0.001    |
|    n_updates       | 429999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 444      |
|    fps             | 65       |
|    time_elapsed    | 6821     |
|    total_timesteps | 444000   |
| train/             |          |
|    actor_loss      | -310     |
|    critic_loss     | 0.0854   |
|    learning_rate   | 0.001    |
|    n_updates       | 433999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 448      |
|    fps             | 65       |
|    time_elapsed    | 6883     |
|    total_timesteps | 448000   |
| train/             |          |
|    actor_loss      | -313     |
|    critic_loss     | 0.15     |
|    learning_rate   | 0.001    |
|    n_updates       | 437999   |
---------------------------------
Eval num_timesteps=450000, episode_reward=353.37 +/- 2.24
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 353      |
| time/              |          |
|    total_timesteps | 450000   |
| train/             |          |
|    actor_loss      | -320     |
|    critic_loss     | 0.124    |
|    learning_rate   | 0.001    |
|    n_updates       | 439999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 452      |
|    fps             | 65       |
|    time_elapsed    | 6949     |
|    total_timesteps | 452000   |
| train/             |          |
|    actor_loss      | -319     |
|    critic_loss     | 0.127    |
|    learning_rate   | 0.001    |
|    n_updates       | 441999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 456      |
|    fps             | 64       |
|    time_elapsed    | 7022     |
|    total_timesteps | 456000   |
| train/             |          |
|    actor_loss      | -322     |
|    critic_loss     | 0.148    |
|    learning_rate   | 0.001    |
|    n_updates       | 445999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 460      |
|    fps             | 64       |
|    time_elapsed    | 7088     |
|    total_timesteps | 460000   |
| train/             |          |
|    actor_loss      | -329     |
|    critic_loss     | 0.131    |
|    learning_rate   | 0.001    |
|    n_updates       | 449999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 464      |
|    fps             | 64       |
|    time_elapsed    | 7153     |
|    total_timesteps | 464000   |
| train/             |          |
|    actor_loss      | -327     |
|    critic_loss     | 0.0948   |
|    learning_rate   | 0.001    |
|    n_updates       | 453999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 468      |
|    fps             | 64       |
|    time_elapsed    | 7218     |
|    total_timesteps | 468000   |
| train/             |          |
|    actor_loss      | -331     |
|    critic_loss     | 0.186    |
|    learning_rate   | 0.001    |
|    n_updates       | 457999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 472      |
|    fps             | 64       |
|    time_elapsed    | 7284     |
|    total_timesteps | 472000   |
| train/             |          |
|    actor_loss      | -335     |
|    critic_loss     | 0.214    |
|    learning_rate   | 0.001    |
|    n_updates       | 461999   |
---------------------------------
Eval num_timesteps=475000, episode_reward=353.31 +/- 2.31
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 353      |
| time/              |          |
|    total_timesteps | 475000   |
| train/             |          |
|    actor_loss      | -339     |
|    critic_loss     | 0.107    |
|    learning_rate   | 0.001    |
|    n_updates       | 464999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 344      |
| time/              |          |
|    episodes        | 476      |
|    fps             | 64       |
|    time_elapsed    | 7365     |
|    total_timesteps | 476000   |
| train/             |          |
|    actor_loss      | -338     |
|    critic_loss     | 0.067    |
|    learning_rate   | 0.001    |
|    n_updates       | 465999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 344      |
| time/              |          |
|    episodes        | 480      |
|    fps             | 64       |
|    time_elapsed    | 7416     |
|    total_timesteps | 480000   |
| train/             |          |
|    actor_loss      | -344     |
|    critic_loss     | 0.131    |
|    learning_rate   | 0.001    |
|    n_updates       | 469999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 344      |
| time/              |          |
|    episodes        | 484      |
|    fps             | 64       |
|    time_elapsed    | 7466     |
|    total_timesteps | 484000   |
| train/             |          |
|    actor_loss      | -343     |
|    critic_loss     | 0.136    |
|    learning_rate   | 0.001    |
|    n_updates       | 473999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 344      |
| time/              |          |
|    episodes        | 488      |
|    fps             | 64       |
|    time_elapsed    | 7525     |
|    total_timesteps | 488000   |
| train/             |          |
|    actor_loss      | -348     |
|    critic_loss     | 0.188    |
|    learning_rate   | 0.001    |
|    n_updates       | 477999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 344      |
| time/              |          |
|    episodes        | 492      |
|    fps             | 64       |
|    time_elapsed    | 7584     |
|    total_timesteps | 492000   |
| train/             |          |
|    actor_loss      | -353     |
|    critic_loss     | 0.257    |
|    learning_rate   | 0.001    |
|    n_updates       | 481999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 344      |
| time/              |          |
|    episodes        | 496      |
|    fps             | 64       |
|    time_elapsed    | 7639     |
|    total_timesteps | 496000   |
| train/             |          |
|    actor_loss      | -350     |
|    critic_loss     | 0.15     |
|    learning_rate   | 0.001    |
|    n_updates       | 485999   |
---------------------------------
Eval num_timesteps=500000, episode_reward=356.30 +/- 2.30
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 356      |
| time/              |          |
|    total_timesteps | 500000   |
| train/             |          |
|    actor_loss      | -354     |
|    critic_loss     | 0.237    |
|    learning_rate   | 0.001    |
|    n_updates       | 489999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 344      |
| time/              |          |
|    episodes        | 500      |
|    fps             | 64       |
|    time_elapsed    | 7697     |
|    total_timesteps | 500000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 504      |
|    fps             | 64       |
|    time_elapsed    | 7758     |
|    total_timesteps | 504000   |
| train/             |          |
|    actor_loss      | -361     |
|    critic_loss     | 0.166    |
|    learning_rate   | 0.001    |
|    n_updates       | 493999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 508      |
|    fps             | 64       |
|    time_elapsed    | 7816     |
|    total_timesteps | 508000   |
| train/             |          |
|    actor_loss      | -372     |
|    critic_loss     | 0.138    |
|    learning_rate   | 0.001    |
|    n_updates       | 497999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 512      |
|    fps             | 65       |
|    time_elapsed    | 7874     |
|    total_timesteps | 512000   |
| train/             |          |
|    actor_loss      | -364     |
|    critic_loss     | 0.0965   |
|    learning_rate   | 0.001    |
|    n_updates       | 501999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 516      |
|    fps             | 65       |
|    time_elapsed    | 7934     |
|    total_timesteps | 516000   |
| train/             |          |
|    actor_loss      | -374     |
|    critic_loss     | 0.159    |
|    learning_rate   | 0.001    |
|    n_updates       | 505999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 520      |
|    fps             | 65       |
|    time_elapsed    | 7991     |
|    total_timesteps | 520000   |
| train/             |          |
|    actor_loss      | -369     |
|    critic_loss     | 0.162    |
|    learning_rate   | 0.001    |
|    n_updates       | 509999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 524      |
|    fps             | 65       |
|    time_elapsed    | 8048     |
|    total_timesteps | 524000   |
| train/             |          |
|    actor_loss      | -373     |
|    critic_loss     | 0.136    |
|    learning_rate   | 0.001    |
|    n_updates       | 513999   |
---------------------------------
Eval num_timesteps=525000, episode_reward=354.02 +/- 1.29
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 354      |
| time/              |          |
|    total_timesteps | 525000   |
| train/             |          |
|    actor_loss      | -374     |
|    critic_loss     | 0.191    |
|    learning_rate   | 0.001    |
|    n_updates       | 514999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 345      |
| time/              |          |
|    episodes        | 528      |
|    fps             | 65       |
|    time_elapsed    | 8109     |
|    total_timesteps | 528000   |
| train/             |          |
|    actor_loss      | -384     |
|    critic_loss     | 0.165    |
|    learning_rate   | 0.001    |
|    n_updates       | 517999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 342      |
| time/              |          |
|    episodes        | 532      |
|    fps             | 65       |
|    time_elapsed    | 8167     |
|    total_timesteps | 532000   |
| train/             |          |
|    actor_loss      | -380     |
|    critic_loss     | 0.284    |
|    learning_rate   | 0.001    |
|    n_updates       | 521999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 330      |
| time/              |          |
|    episodes        | 536      |
|    fps             | 65       |
|    time_elapsed    | 8227     |
|    total_timesteps | 536000   |
| train/             |          |
|    actor_loss      | -388     |
|    critic_loss     | 0.184    |
|    learning_rate   | 0.001    |
|    n_updates       | 525999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 317      |
| time/              |          |
|    episodes        | 540      |
|    fps             | 65       |
|    time_elapsed    | 8286     |
|    total_timesteps | 540000   |
| train/             |          |
|    actor_loss      | -393     |
|    critic_loss     | 0.913    |
|    learning_rate   | 0.001    |
|    n_updates       | 529999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 316      |
| time/              |          |
|    episodes        | 544      |
|    fps             | 65       |
|    time_elapsed    | 8343     |
|    total_timesteps | 544000   |
| train/             |          |
|    actor_loss      | -396     |
|    critic_loss     | 0.178    |
|    learning_rate   | 0.001    |
|    n_updates       | 533999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 304      |
| time/              |          |
|    episodes        | 548      |
|    fps             | 65       |
|    time_elapsed    | 8401     |
|    total_timesteps | 548000   |
| train/             |          |
|    actor_loss      | -397     |
|    critic_loss     | 0.41     |
|    learning_rate   | 0.001    |
|    n_updates       | 537999   |
---------------------------------
Eval num_timesteps=550000, episode_reward=10.09 +/- 4.46
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 10.1     |
| time/              |          |
|    total_timesteps | 550000   |
| train/             |          |
|    actor_loss      | -402     |
|    critic_loss     | 0.481    |
|    learning_rate   | 0.001    |
|    n_updates       | 539999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 291      |
| time/              |          |
|    episodes        | 552      |
|    fps             | 65       |
|    time_elapsed    | 8461     |
|    total_timesteps | 552000   |
| train/             |          |
|    actor_loss      | -404     |
|    critic_loss     | 0.393    |
|    learning_rate   | 0.001    |
|    n_updates       | 541999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 278      |
| time/              |          |
|    episodes        | 556      |
|    fps             | 65       |
|    time_elapsed    | 8519     |
|    total_timesteps | 556000   |
| train/             |          |
|    actor_loss      | -422     |
|    critic_loss     | 0.201    |
|    learning_rate   | 0.001    |
|    n_updates       | 545999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 265      |
| time/              |          |
|    episodes        | 560      |
|    fps             | 65       |
|    time_elapsed    | 8577     |
|    total_timesteps | 560000   |
| train/             |          |
|    actor_loss      | -415     |
|    critic_loss     | 0.356    |
|    learning_rate   | 0.001    |
|    n_updates       | 549999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 251      |
| time/              |          |
|    episodes        | 564      |
|    fps             | 65       |
|    time_elapsed    | 8637     |
|    total_timesteps | 564000   |
| train/             |          |
|    actor_loss      | -420     |
|    critic_loss     | 0.517    |
|    learning_rate   | 0.001    |
|    n_updates       | 553999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 239      |
| time/              |          |
|    episodes        | 568      |
|    fps             | 65       |
|    time_elapsed    | 8690     |
|    total_timesteps | 568000   |
| train/             |          |
|    actor_loss      | -426     |
|    critic_loss     | 0.447    |
|    learning_rate   | 0.001    |
|    n_updates       | 557999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 225      |
| time/              |          |
|    episodes        | 572      |
|    fps             | 65       |
|    time_elapsed    | 8740     |
|    total_timesteps | 572000   |
| train/             |          |
|    actor_loss      | -435     |
|    critic_loss     | 0.548    |
|    learning_rate   | 0.001    |
|    n_updates       | 561999   |
---------------------------------
Eval num_timesteps=575000, episode_reward=21.95 +/- 4.20
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 22       |
| time/              |          |
|    total_timesteps | 575000   |
| train/             |          |
|    actor_loss      | -449     |
|    critic_loss     | 0.577    |
|    learning_rate   | 0.001    |
|    n_updates       | 564999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 211      |
| time/              |          |
|    episodes        | 576      |
|    fps             | 65       |
|    time_elapsed    | 8795     |
|    total_timesteps | 576000   |
| train/             |          |
|    actor_loss      | -444     |
|    critic_loss     | 0.498    |
|    learning_rate   | 0.001    |
|    n_updates       | 565999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 199      |
| time/              |          |
|    episodes        | 580      |
|    fps             | 65       |
|    time_elapsed    | 8848     |
|    total_timesteps | 580000   |
| train/             |          |
|    actor_loss      | -441     |
|    critic_loss     | 0.356    |
|    learning_rate   | 0.001    |
|    n_updates       | 569999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 187      |
| time/              |          |
|    episodes        | 584      |
|    fps             | 65       |
|    time_elapsed    | 8905     |
|    total_timesteps | 584000   |
| train/             |          |
|    actor_loss      | -456     |
|    critic_loss     | 0.869    |
|    learning_rate   | 0.001    |
|    n_updates       | 573999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 174      |
| time/              |          |
|    episodes        | 588      |
|    fps             | 65       |
|    time_elapsed    | 8964     |
|    total_timesteps | 588000   |
| train/             |          |
|    actor_loss      | -456     |
|    critic_loss     | 0.326    |
|    learning_rate   | 0.001    |
|    n_updates       | 577999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 160      |
| time/              |          |
|    episodes        | 592      |
|    fps             | 65       |
|    time_elapsed    | 9023     |
|    total_timesteps | 592000   |
| train/             |          |
|    actor_loss      | -473     |
|    critic_loss     | 0.601    |
|    learning_rate   | 0.001    |
|    n_updates       | 581999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 147      |
| time/              |          |
|    episodes        | 596      |
|    fps             | 65       |
|    time_elapsed    | 9084     |
|    total_timesteps | 596000   |
| train/             |          |
|    actor_loss      | -467     |
|    critic_loss     | 0.56     |
|    learning_rate   | 0.001    |
|    n_updates       | 585999   |
---------------------------------
Eval num_timesteps=600000, episode_reward=9.02 +/- 1.20
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 9.02     |
| time/              |          |
|    total_timesteps | 600000   |
| train/             |          |
|    actor_loss      | -482     |
|    critic_loss     | 0.657    |
|    learning_rate   | 0.001    |
|    n_updates       | 589999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 134      |
| time/              |          |
|    episodes        | 600      |
|    fps             | 65       |
|    time_elapsed    | 9151     |
|    total_timesteps | 600000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 120      |
| time/              |          |
|    episodes        | 604      |
|    fps             | 65       |
|    time_elapsed    | 9213     |
|    total_timesteps | 604000   |
| train/             |          |
|    actor_loss      | -490     |
|    critic_loss     | 0.593    |
|    learning_rate   | 0.001    |
|    n_updates       | 593999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 106      |
| time/              |          |
|    episodes        | 608      |
|    fps             | 65       |
|    time_elapsed    | 9274     |
|    total_timesteps | 608000   |
| train/             |          |
|    actor_loss      | -471     |
|    critic_loss     | 0.449    |
|    learning_rate   | 0.001    |
|    n_updates       | 597999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 92.3     |
| time/              |          |
|    episodes        | 612      |
|    fps             | 65       |
|    time_elapsed    | 9331     |
|    total_timesteps | 612000   |
| train/             |          |
|    actor_loss      | -500     |
|    critic_loss     | 0.53     |
|    learning_rate   | 0.001    |
|    n_updates       | 601999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 78.4     |
| time/              |          |
|    episodes        | 616      |
|    fps             | 65       |
|    time_elapsed    | 9390     |
|    total_timesteps | 616000   |
| train/             |          |
|    actor_loss      | -514     |
|    critic_loss     | 0.737    |
|    learning_rate   | 0.001    |
|    n_updates       | 605999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 65.3     |
| time/              |          |
|    episodes        | 620      |
|    fps             | 65       |
|    time_elapsed    | 9445     |
|    total_timesteps | 620000   |
| train/             |          |
|    actor_loss      | -528     |
|    critic_loss     | 0.567    |
|    learning_rate   | 0.001    |
|    n_updates       | 609999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 52.1     |
| time/              |          |
|    episodes        | 624      |
|    fps             | 65       |
|    time_elapsed    | 9502     |
|    total_timesteps | 624000   |
| train/             |          |
|    actor_loss      | -532     |
|    critic_loss     | 0.526    |
|    learning_rate   | 0.001    |
|    n_updates       | 613999   |
---------------------------------
Eval num_timesteps=625000, episode_reward=-1.43 +/- 1.92
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | -1.43    |
| time/              |          |
|    total_timesteps | 625000   |
| train/             |          |
|    actor_loss      | -525     |
|    critic_loss     | 0.282    |
|    learning_rate   | 0.001    |
|    n_updates       | 614999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 39.5     |
| time/              |          |
|    episodes        | 628      |
|    fps             | 65       |
|    time_elapsed    | 9566     |
|    total_timesteps | 628000   |
| train/             |          |
|    actor_loss      | -514     |
|    critic_loss     | 0.469    |
|    learning_rate   | 0.001    |
|    n_updates       | 617999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 29.4     |
| time/              |          |
|    episodes        | 632      |
|    fps             | 65       |
|    time_elapsed    | 9624     |
|    total_timesteps | 632000   |
| train/             |          |
|    actor_loss      | -542     |
|    critic_loss     | 0.627    |
|    learning_rate   | 0.001    |
|    n_updates       | 621999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 28.7     |
| time/              |          |
|    episodes        | 636      |
|    fps             | 65       |
|    time_elapsed    | 9682     |
|    total_timesteps | 636000   |
| train/             |          |
|    actor_loss      | -530     |
|    critic_loss     | 0.909    |
|    learning_rate   | 0.001    |
|    n_updates       | 625999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 28.3     |
| time/              |          |
|    episodes        | 640      |
|    fps             | 65       |
|    time_elapsed    | 9736     |
|    total_timesteps | 640000   |
| train/             |          |
|    actor_loss      | -583     |
|    critic_loss     | 0.531    |
|    learning_rate   | 0.001    |
|    n_updates       | 629999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 16.4     |
| time/              |          |
|    episodes        | 644      |
|    fps             | 65       |
|    time_elapsed    | 9795     |
|    total_timesteps | 644000   |
| train/             |          |
|    actor_loss      | -576     |
|    critic_loss     | 1.19     |
|    learning_rate   | 0.001    |
|    n_updates       | 633999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 14.5     |
| time/              |          |
|    episodes        | 648      |
|    fps             | 65       |
|    time_elapsed    | 9854     |
|    total_timesteps | 648000   |
| train/             |          |
|    actor_loss      | -565     |
|    critic_loss     | 1.55     |
|    learning_rate   | 0.001    |
|    n_updates       | 637999   |
---------------------------------
Eval num_timesteps=650000, episode_reward=32.02 +/- 1.86
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 32       |
| time/              |          |
|    total_timesteps | 650000   |
| train/             |          |
|    actor_loss      | -569     |
|    critic_loss     | 1.13     |
|    learning_rate   | 0.001    |
|    n_updates       | 639999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 14.5     |
| time/              |          |
|    episodes        | 652      |
|    fps             | 65       |
|    time_elapsed    | 9915     |
|    total_timesteps | 652000   |
| train/             |          |
|    actor_loss      | -597     |
|    critic_loss     | 0.845    |
|    learning_rate   | 0.001    |
|    n_updates       | 641999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 14.4     |
| time/              |          |
|    episodes        | 656      |
|    fps             | 65       |
|    time_elapsed    | 9972     |
|    total_timesteps | 656000   |
| train/             |          |
|    actor_loss      | -570     |
|    critic_loss     | 1.04     |
|    learning_rate   | 0.001    |
|    n_updates       | 645999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 14.4     |
| time/              |          |
|    episodes        | 660      |
|    fps             | 65       |
|    time_elapsed    | 10031    |
|    total_timesteps | 660000   |
| train/             |          |
|    actor_loss      | -628     |
|    critic_loss     | 0.521    |
|    learning_rate   | 0.001    |
|    n_updates       | 649999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 14.1     |
| time/              |          |
|    episodes        | 664      |
|    fps             | 65       |
|    time_elapsed    | 10089    |
|    total_timesteps | 664000   |
| train/             |          |
|    actor_loss      | -597     |
|    critic_loss     | 1.18     |
|    learning_rate   | 0.001    |
|    n_updates       | 653999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 13.5     |
| time/              |          |
|    episodes        | 668      |
|    fps             | 65       |
|    time_elapsed    | 10147    |
|    total_timesteps | 668000   |
| train/             |          |
|    actor_loss      | -635     |
|    critic_loss     | 0.924    |
|    learning_rate   | 0.001    |
|    n_updates       | 657999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 13.5     |
| time/              |          |
|    episodes        | 672      |
|    fps             | 65       |
|    time_elapsed    | 10208    |
|    total_timesteps | 672000   |
| train/             |          |
|    actor_loss      | -616     |
|    critic_loss     | 1.42     |
|    learning_rate   | 0.001    |
|    n_updates       | 661999   |
---------------------------------
Eval num_timesteps=675000, episode_reward=-17.58 +/- 8.64
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | -17.6    |
| time/              |          |
|    total_timesteps | 675000   |
| train/             |          |
|    actor_loss      | -662     |
|    critic_loss     | 0.955    |
|    learning_rate   | 0.001    |
|    n_updates       | 664999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 13.5     |
| time/              |          |
|    episodes        | 676      |
|    fps             | 65       |
|    time_elapsed    | 10266    |
|    total_timesteps | 676000   |
| train/             |          |
|    actor_loss      | -604     |
|    critic_loss     | 1.1      |
|    learning_rate   | 0.001    |
|    n_updates       | 665999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 11.8     |
| time/              |          |
|    episodes        | 680      |
|    fps             | 65       |
|    time_elapsed    | 10321    |
|    total_timesteps | 680000   |
| train/             |          |
|    actor_loss      | -669     |
|    critic_loss     | 2.12     |
|    learning_rate   | 0.001    |
|    n_updates       | 669999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 10.4     |
| time/              |          |
|    episodes        | 684      |
|    fps             | 65       |
|    time_elapsed    | 10380    |
|    total_timesteps | 684000   |
| train/             |          |
|    actor_loss      | -628     |
|    critic_loss     | 1.7      |
|    learning_rate   | 0.001    |
|    n_updates       | 673999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 9.8      |
| time/              |          |
|    episodes        | 688      |
|    fps             | 65       |
|    time_elapsed    | 10436    |
|    total_timesteps | 688000   |
| train/             |          |
|    actor_loss      | -646     |
|    critic_loss     | 1.18     |
|    learning_rate   | 0.001    |
|    n_updates       | 677999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 9.65     |
| time/              |          |
|    episodes        | 692      |
|    fps             | 65       |
|    time_elapsed    | 10495    |
|    total_timesteps | 692000   |
| train/             |          |
|    actor_loss      | -683     |
|    critic_loss     | 2.76     |
|    learning_rate   | 0.001    |
|    n_updates       | 681999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 9.02     |
| time/              |          |
|    episodes        | 696      |
|    fps             | 65       |
|    time_elapsed    | 10550    |
|    total_timesteps | 696000   |
| train/             |          |
|    actor_loss      | -680     |
|    critic_loss     | 1.49     |
|    learning_rate   | 0.001    |
|    n_updates       | 685999   |
---------------------------------
Eval num_timesteps=700000, episode_reward=26.03 +/- 0.80
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 26       |
| time/              |          |
|    total_timesteps | 700000   |
| train/             |          |
|    actor_loss      | -758     |
|    critic_loss     | 1.2      |
|    learning_rate   | 0.001    |
|    n_updates       | 689999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 9.22     |
| time/              |          |
|    episodes        | 700      |
|    fps             | 65       |
|    time_elapsed    | 10606    |
|    total_timesteps | 700000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 9.68     |
| time/              |          |
|    episodes        | 704      |
|    fps             | 66       |
|    time_elapsed    | 10658    |
|    total_timesteps | 704000   |
| train/             |          |
|    actor_loss      | -726     |
|    critic_loss     | 2.92     |
|    learning_rate   | 0.001    |
|    n_updates       | 693999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 9.4      |
| time/              |          |
|    episodes        | 708      |
|    fps             | 66       |
|    time_elapsed    | 10720    |
|    total_timesteps | 708000   |
| train/             |          |
|    actor_loss      | -727     |
|    critic_loss     | 5.21     |
|    learning_rate   | 0.001    |
|    n_updates       | 697999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 10.1     |
| time/              |          |
|    episodes        | 712      |
|    fps             | 65       |
|    time_elapsed    | 10798    |
|    total_timesteps | 712000   |
| train/             |          |
|    actor_loss      | -742     |
|    critic_loss     | 2.95     |
|    learning_rate   | 0.001    |
|    n_updates       | 701999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 11       |
| time/              |          |
|    episodes        | 716      |
|    fps             | 65       |
|    time_elapsed    | 10857    |
|    total_timesteps | 716000   |
| train/             |          |
|    actor_loss      | -715     |
|    critic_loss     | 1.32     |
|    learning_rate   | 0.001    |
|    n_updates       | 705999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 10.7     |
| time/              |          |
|    episodes        | 720      |
|    fps             | 65       |
|    time_elapsed    | 10914    |
|    total_timesteps | 720000   |
| train/             |          |
|    actor_loss      | -757     |
|    critic_loss     | 2.16     |
|    learning_rate   | 0.001    |
|    n_updates       | 709999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 10.9     |
| time/              |          |
|    episodes        | 724      |
|    fps             | 65       |
|    time_elapsed    | 10971    |
|    total_timesteps | 724000   |
| train/             |          |
|    actor_loss      | -771     |
|    critic_loss     | 4.68     |
|    learning_rate   | 0.001    |
|    n_updates       | 713999   |
---------------------------------
Eval num_timesteps=725000, episode_reward=16.70 +/- 0.55
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 16.7     |
| time/              |          |
|    total_timesteps | 725000   |
| train/             |          |
|    actor_loss      | -769     |
|    critic_loss     | 1.43     |
|    learning_rate   | 0.001    |
|    n_updates       | 714999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 10.6     |
| time/              |          |
|    episodes        | 728      |
|    fps             | 65       |
|    time_elapsed    | 11030    |
|    total_timesteps | 728000   |
| train/             |          |
|    actor_loss      | -781     |
|    critic_loss     | 2.15     |
|    learning_rate   | 0.001    |
|    n_updates       | 717999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 10.4     |
| time/              |          |
|    episodes        | 732      |
|    fps             | 66       |
|    time_elapsed    | 11089    |
|    total_timesteps | 732000   |
| train/             |          |
|    actor_loss      | -787     |
|    critic_loss     | 1.13     |
|    learning_rate   | 0.001    |
|    n_updates       | 721999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 10.4     |
| time/              |          |
|    episodes        | 736      |
|    fps             | 66       |
|    time_elapsed    | 11146    |
|    total_timesteps | 736000   |
| train/             |          |
|    actor_loss      | -768     |
|    critic_loss     | 1.87     |
|    learning_rate   | 0.001    |
|    n_updates       | 725999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 10.4     |
| time/              |          |
|    episodes        | 740      |
|    fps             | 66       |
|    time_elapsed    | 11203    |
|    total_timesteps | 740000   |
| train/             |          |
|    actor_loss      | -804     |
|    critic_loss     | 2.45     |
|    learning_rate   | 0.001    |
|    n_updates       | 729999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 10.2     |
| time/              |          |
|    episodes        | 744      |
|    fps             | 66       |
|    time_elapsed    | 11260    |
|    total_timesteps | 744000   |
| train/             |          |
|    actor_loss      | -780     |
|    critic_loss     | 0.674    |
|    learning_rate   | 0.001    |
|    n_updates       | 733999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 9.89     |
| time/              |          |
|    episodes        | 748      |
|    fps             | 66       |
|    time_elapsed    | 11317    |
|    total_timesteps | 748000   |
| train/             |          |
|    actor_loss      | -807     |
|    critic_loss     | 1.7      |
|    learning_rate   | 0.001    |
|    n_updates       | 737999   |
---------------------------------
Eval num_timesteps=750000, episode_reward=30.09 +/- 0.97
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 30.1     |
| time/              |          |
|    total_timesteps | 750000   |
| train/             |          |
|    actor_loss      | -807     |
|    critic_loss     | 2.42     |
|    learning_rate   | 0.001    |
|    n_updates       | 739999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 9.54     |
| time/              |          |
|    episodes        | 752      |
|    fps             | 66       |
|    time_elapsed    | 11376    |
|    total_timesteps | 752000   |
| train/             |          |
|    actor_loss      | -850     |
|    critic_loss     | 0.839    |
|    learning_rate   | 0.001    |
|    n_updates       | 741999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 9.08     |
| time/              |          |
|    episodes        | 756      |
|    fps             | 66       |
|    time_elapsed    | 11434    |
|    total_timesteps | 756000   |
| train/             |          |
|    actor_loss      | -868     |
|    critic_loss     | 2.14     |
|    learning_rate   | 0.001    |
|    n_updates       | 745999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 8.61     |
| time/              |          |
|    episodes        | 760      |
|    fps             | 66       |
|    time_elapsed    | 11490    |
|    total_timesteps | 760000   |
| train/             |          |
|    actor_loss      | -864     |
|    critic_loss     | 4.8      |
|    learning_rate   | 0.001    |
|    n_updates       | 749999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 8.72     |
| time/              |          |
|    episodes        | 764      |
|    fps             | 66       |
|    time_elapsed    | 11547    |
|    total_timesteps | 764000   |
| train/             |          |
|    actor_loss      | -816     |
|    critic_loss     | 2.43     |
|    learning_rate   | 0.001    |
|    n_updates       | 753999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 8.95     |
| time/              |          |
|    episodes        | 768      |
|    fps             | 66       |
|    time_elapsed    | 11604    |
|    total_timesteps | 768000   |
| train/             |          |
|    actor_loss      | -867     |
|    critic_loss     | 3.07     |
|    learning_rate   | 0.001    |
|    n_updates       | 757999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 8.9      |
| time/              |          |
|    episodes        | 772      |
|    fps             | 66       |
|    time_elapsed    | 11661    |
|    total_timesteps | 772000   |
| train/             |          |
|    actor_loss      | -855     |
|    critic_loss     | 1.6      |
|    learning_rate   | 0.001    |
|    n_updates       | 761999   |
---------------------------------
Eval num_timesteps=775000, episode_reward=0.56 +/- 4.47
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 0.56     |
| time/              |          |
|    total_timesteps | 775000   |
| train/             |          |
|    actor_loss      | -870     |
|    critic_loss     | 1.49     |
|    learning_rate   | 0.001    |
|    n_updates       | 764999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 9.35     |
| time/              |          |
|    episodes        | 776      |
|    fps             | 66       |
|    time_elapsed    | 11716    |
|    total_timesteps | 776000   |
| train/             |          |
|    actor_loss      | -876     |
|    critic_loss     | 1.04     |
|    learning_rate   | 0.001    |
|    n_updates       | 765999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 9.69     |
| time/              |          |
|    episodes        | 780      |
|    fps             | 66       |
|    time_elapsed    | 11775    |
|    total_timesteps | 780000   |
| train/             |          |
|    actor_loss      | -878     |
|    critic_loss     | 3.02     |
|    learning_rate   | 0.001    |
|    n_updates       | 769999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 9.71     |
| time/              |          |
|    episodes        | 784      |
|    fps             | 66       |
|    time_elapsed    | 11828    |
|    total_timesteps | 784000   |
| train/             |          |
|    actor_loss      | -913     |
|    critic_loss     | 2.63     |
|    learning_rate   | 0.001    |
|    n_updates       | 773999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 9.48     |
| time/              |          |
|    episodes        | 788      |
|    fps             | 66       |
|    time_elapsed    | 11881    |
|    total_timesteps | 788000   |
| train/             |          |
|    actor_loss      | -893     |
|    critic_loss     | 1.73     |
|    learning_rate   | 0.001    |
|    n_updates       | 777999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 9.97     |
| time/              |          |
|    episodes        | 792      |
|    fps             | 66       |
|    time_elapsed    | 11935    |
|    total_timesteps | 792000   |
| train/             |          |
|    actor_loss      | -990     |
|    critic_loss     | 1.82     |
|    learning_rate   | 0.001    |
|    n_updates       | 781999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 10.6     |
| time/              |          |
|    episodes        | 796      |
|    fps             | 66       |
|    time_elapsed    | 11989    |
|    total_timesteps | 796000   |
| train/             |          |
|    actor_loss      | -988     |
|    critic_loss     | 4.81     |
|    learning_rate   | 0.001    |
|    n_updates       | 785999   |
---------------------------------
Eval num_timesteps=800000, episode_reward=-1.50 +/- 15.00
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | -1.5     |
| time/              |          |
|    total_timesteps | 800000   |
| train/             |          |
|    actor_loss      | -916     |
|    critic_loss     | 1.86     |
|    learning_rate   | 0.001    |
|    n_updates       | 789999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 10.9     |
| time/              |          |
|    episodes        | 800      |
|    fps             | 66       |
|    time_elapsed    | 12045    |
|    total_timesteps | 800000   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 11.2     |
| time/              |          |
|    episodes        | 804      |
|    fps             | 66       |
|    time_elapsed    | 12099    |
|    total_timesteps | 804000   |
| train/             |          |
|    actor_loss      | -992     |
|    critic_loss     | 2.78     |
|    learning_rate   | 0.001    |
|    n_updates       | 793999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 11.6     |
| time/              |          |
|    episodes        | 808      |
|    fps             | 66       |
|    time_elapsed    | 12152    |
|    total_timesteps | 808000   |
| train/             |          |
|    actor_loss      | -1e+03   |
|    critic_loss     | 1.38     |
|    learning_rate   | 0.001    |
|    n_updates       | 797999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 12.3     |
| time/              |          |
|    episodes        | 812      |
|    fps             | 66       |
|    time_elapsed    | 12201    |
|    total_timesteps | 812000   |
| train/             |          |
|    actor_loss      | -977     |
|    critic_loss     | 3.07     |
|    learning_rate   | 0.001    |
|    n_updates       | 801999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 12.3     |
| time/              |          |
|    episodes        | 816      |
|    fps             | 66       |
|    time_elapsed    | 12250    |
|    total_timesteps | 816000   |
| train/             |          |
|    actor_loss      | -985     |
|    critic_loss     | 1.98     |
|    learning_rate   | 0.001    |
|    n_updates       | 805999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 12.8     |
| time/              |          |
|    episodes        | 820      |
|    fps             | 66       |
|    time_elapsed    | 12299    |
|    total_timesteps | 820000   |
| train/             |          |
|    actor_loss      | -961     |
|    critic_loss     | 2.25     |
|    learning_rate   | 0.001    |
|    n_updates       | 809999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 13.3     |
| time/              |          |
|    episodes        | 824      |
|    fps             | 66       |
|    time_elapsed    | 12346    |
|    total_timesteps | 824000   |
| train/             |          |
|    actor_loss      | -997     |
|    critic_loss     | 2.64     |
|    learning_rate   | 0.001    |
|    n_updates       | 813999   |
---------------------------------
Eval num_timesteps=825000, episode_reward=38.26 +/- 1.80
Episode length: 1000.00 +/- 0.00
----------------------------------
| eval/              |           |
|    mean_ep_length  | 1e+03     |
|    mean_reward     | 38.3      |
| time/              |           |
|    total_timesteps | 825000    |
| train/             |           |
|    actor_loss      | -1.01e+03 |
|    critic_loss     | 1.71      |
|    learning_rate   | 0.001     |
|    n_updates       | 814999    |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 13.2      |
| time/              |           |
|    episodes        | 828       |
|    fps             | 66        |
|    time_elapsed    | 12397     |
|    total_timesteps | 828000    |
| train/             |           |
|    actor_loss      | -1.06e+03 |
|    critic_loss     | 1.66      |
|    learning_rate   | 0.001     |
|    n_updates       | 817999    |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 13.3      |
| time/              |           |
|    episodes        | 832       |
|    fps             | 66        |
|    time_elapsed    | 12444     |
|    total_timesteps | 832000    |
| train/             |           |
|    actor_loss      | -1.04e+03 |
|    critic_loss     | 2         |
|    learning_rate   | 0.001     |
|    n_updates       | 821999    |
----------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 13       |
| time/              |          |
|    episodes        | 836      |
|    fps             | 66       |
|    time_elapsed    | 12492    |
|    total_timesteps | 836000   |
| train/             |          |
|    actor_loss      | -1e+03   |
|    critic_loss     | 1.18     |
|    learning_rate   | 0.001    |
|    n_updates       | 825999   |
---------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 12.5      |
| time/              |           |
|    episodes        | 840       |
|    fps             | 66        |
|    time_elapsed    | 12540     |
|    total_timesteps | 840000    |
| train/             |           |
|    actor_loss      | -1.07e+03 |
|    critic_loss     | 2.11      |
|    learning_rate   | 0.001     |
|    n_updates       | 829999    |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 12.9      |
| time/              |           |
|    episodes        | 844       |
|    fps             | 67        |
|    time_elapsed    | 12588     |
|    total_timesteps | 844000    |
| train/             |           |
|    actor_loss      | -1.06e+03 |
|    critic_loss     | 2.07      |
|    learning_rate   | 0.001     |
|    n_updates       | 833999    |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 13        |
| time/              |           |
|    episodes        | 848       |
|    fps             | 67        |
|    time_elapsed    | 12639     |
|    total_timesteps | 848000    |
| train/             |           |
|    actor_loss      | -1.08e+03 |
|    critic_loss     | 1.31      |
|    learning_rate   | 0.001     |
|    n_updates       | 837999    |
----------------------------------
Eval num_timesteps=850000, episode_reward=1.56 +/- 7.83
Episode length: 1000.00 +/- 0.00
----------------------------------
| eval/              |           |
|    mean_ep_length  | 1e+03     |
|    mean_reward     | 1.56      |
| time/              |           |
|    total_timesteps | 850000    |
| train/             |           |
|    actor_loss      | -1.06e+03 |
|    critic_loss     | 1.84      |
|    learning_rate   | 0.001     |
|    n_updates       | 839999    |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 13.8      |
| time/              |           |
|    episodes        | 852       |
|    fps             | 67        |
|    time_elapsed    | 12689     |
|    total_timesteps | 852000    |
| train/             |           |
|    actor_loss      | -1.07e+03 |
|    critic_loss     | 1.28      |
|    learning_rate   | 0.001     |
|    n_updates       | 841999    |
----------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 14.7     |
| time/              |          |
|    episodes        | 856      |
|    fps             | 67       |
|    time_elapsed    | 12737    |
|    total_timesteps | 856000   |
| train/             |          |
|    actor_loss      | -1.1e+03 |
|    critic_loss     | 1.31     |
|    learning_rate   | 0.001    |
|    n_updates       | 845999   |
---------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 14.8      |
| time/              |           |
|    episodes        | 860       |
|    fps             | 67        |
|    time_elapsed    | 12784     |
|    total_timesteps | 860000    |
| train/             |           |
|    actor_loss      | -1.11e+03 |
|    critic_loss     | 3.89      |
|    learning_rate   | 0.001     |
|    n_updates       | 849999    |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 15.1      |
| time/              |           |
|    episodes        | 864       |
|    fps             | 67        |
|    time_elapsed    | 12832     |
|    total_timesteps | 864000    |
| train/             |           |
|    actor_loss      | -1.09e+03 |
|    critic_loss     | 1.95      |
|    learning_rate   | 0.001     |
|    n_updates       | 853999    |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 14.8      |
| time/              |           |
|    episodes        | 868       |
|    fps             | 67        |
|    time_elapsed    | 12881     |
|    total_timesteps | 868000    |
| train/             |           |
|    actor_loss      | -1.13e+03 |
|    critic_loss     | 2.33      |
|    learning_rate   | 0.001     |
|    n_updates       | 857999    |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 15.2      |
| time/              |           |
|    episodes        | 872       |
|    fps             | 67        |
|    time_elapsed    | 12929     |
|    total_timesteps | 872000    |
| train/             |           |
|    actor_loss      | -1.09e+03 |
|    critic_loss     | 1.64      |
|    learning_rate   | 0.001     |
|    n_updates       | 861999    |
----------------------------------
Eval num_timesteps=875000, episode_reward=-5.03 +/- 0.39
Episode length: 1000.00 +/- 0.00
----------------------------------
| eval/              |           |
|    mean_ep_length  | 1e+03     |
|    mean_reward     | -5.03     |
| time/              |           |
|    total_timesteps | 875000    |
| train/             |           |
|    actor_loss      | -1.08e+03 |
|    critic_loss     | 2.79      |
|    learning_rate   | 0.001     |
|    n_updates       | 864999    |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 14.4      |
| time/              |           |
|    episodes        | 876       |
|    fps             | 67        |
|    time_elapsed    | 12979     |
|    total_timesteps | 876000    |
| train/             |           |
|    actor_loss      | -1.12e+03 |
|    critic_loss     | 2.25      |
|    learning_rate   | 0.001     |
|    n_updates       | 865999    |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 14.5      |
| time/              |           |
|    episodes        | 880       |
|    fps             | 67        |
|    time_elapsed    | 13027     |
|    total_timesteps | 880000    |
| train/             |           |
|    actor_loss      | -1.15e+03 |
|    critic_loss     | 1.48      |
|    learning_rate   | 0.001     |
|    n_updates       | 869999    |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 14.8      |
| time/              |           |
|    episodes        | 884       |
|    fps             | 67        |
|    time_elapsed    | 13075     |
|    total_timesteps | 884000    |
| train/             |           |
|    actor_loss      | -1.13e+03 |
|    critic_loss     | 1.64      |
|    learning_rate   | 0.001     |
|    n_updates       | 873999    |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 15.4      |
| time/              |           |
|    episodes        | 888       |
|    fps             | 67        |
|    time_elapsed    | 13123     |
|    total_timesteps | 888000    |
| train/             |           |
|    actor_loss      | -1.16e+03 |
|    critic_loss     | 1.67      |
|    learning_rate   | 0.001     |
|    n_updates       | 877999    |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 14.9      |
| time/              |           |
|    episodes        | 892       |
|    fps             | 67        |
|    time_elapsed    | 13171     |
|    total_timesteps | 892000    |
| train/             |           |
|    actor_loss      | -1.23e+03 |
|    critic_loss     | 1.39      |
|    learning_rate   | 0.001     |
|    n_updates       | 881999    |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 14.6      |
| time/              |           |
|    episodes        | 896       |
|    fps             | 67        |
|    time_elapsed    | 13218     |
|    total_timesteps | 896000    |
| train/             |           |
|    actor_loss      | -1.18e+03 |
|    critic_loss     | 2.24      |
|    learning_rate   | 0.001     |
|    n_updates       | 885999    |
----------------------------------
Eval num_timesteps=900000, episode_reward=19.06 +/- 1.71
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 19.1     |
| time/              |          |
|    total_timesteps | 900000   |
| train/             |          |
|    actor_loss      | -1.2e+03 |
|    critic_loss     | 1.59     |
|    learning_rate   | 0.001    |
|    n_updates       | 889999   |
---------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 14.1     |
| time/              |          |
|    episodes        | 900      |
|    fps             | 67       |
|    time_elapsed    | 13268    |
|    total_timesteps | 900000   |
---------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 13.5      |
| time/              |           |
|    episodes        | 904       |
|    fps             | 67        |
|    time_elapsed    | 13316     |
|    total_timesteps | 904000    |
| train/             |           |
|    actor_loss      | -1.17e+03 |
|    critic_loss     | 4.12      |
|    learning_rate   | 0.001     |
|    n_updates       | 893999    |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 13.1      |
| time/              |           |
|    episodes        | 908       |
|    fps             | 67        |
|    time_elapsed    | 13363     |
|    total_timesteps | 908000    |
| train/             |           |
|    actor_loss      | -1.21e+03 |
|    critic_loss     | 2.17      |
|    learning_rate   | 0.001     |
|    n_updates       | 897999    |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 13.2      |
| time/              |           |
|    episodes        | 912       |
|    fps             | 68        |
|    time_elapsed    | 13410     |
|    total_timesteps | 912000    |
| train/             |           |
|    actor_loss      | -1.24e+03 |
|    critic_loss     | 2.43      |
|    learning_rate   | 0.001     |
|    n_updates       | 901999    |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 13        |
| time/              |           |
|    episodes        | 916       |
|    fps             | 68        |
|    time_elapsed    | 13458     |
|    total_timesteps | 916000    |
| train/             |           |
|    actor_loss      | -1.24e+03 |
|    critic_loss     | 1.1       |
|    learning_rate   | 0.001     |
|    n_updates       | 905999    |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 12.9      |
| time/              |           |
|    episodes        | 920       |
|    fps             | 68        |
|    time_elapsed    | 13509     |
|    total_timesteps | 920000    |
| train/             |           |
|    actor_loss      | -1.29e+03 |
|    critic_loss     | 1.96      |
|    learning_rate   | 0.001     |
|    n_updates       | 909999    |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 12.4      |
| time/              |           |
|    episodes        | 924       |
|    fps             | 68        |
|    time_elapsed    | 13585     |
|    total_timesteps | 924000    |
| train/             |           |
|    actor_loss      | -1.27e+03 |
|    critic_loss     | 4.55      |
|    learning_rate   | 0.001     |
|    n_updates       | 913999    |
----------------------------------
Eval num_timesteps=925000, episode_reward=18.95 +/- 0.74
Episode length: 1000.00 +/- 0.00
----------------------------------
| eval/              |           |
|    mean_ep_length  | 1e+03     |
|    mean_reward     | 19        |
| time/              |           |
|    total_timesteps | 925000    |
| train/             |           |
|    actor_loss      | -1.23e+03 |
|    critic_loss     | 1.1       |
|    learning_rate   | 0.001     |
|    n_updates       | 914999    |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 12.7      |
| time/              |           |
|    episodes        | 928       |
|    fps             | 68        |
|    time_elapsed    | 13639     |
|    total_timesteps | 928000    |
| train/             |           |
|    actor_loss      | -1.27e+03 |
|    critic_loss     | 1.54      |
|    learning_rate   | 0.001     |
|    n_updates       | 917999    |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 12.9      |
| time/              |           |
|    episodes        | 932       |
|    fps             | 68        |
|    time_elapsed    | 13689     |
|    total_timesteps | 932000    |
| train/             |           |
|    actor_loss      | -1.26e+03 |
|    critic_loss     | 1.59      |
|    learning_rate   | 0.001     |
|    n_updates       | 921999    |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 13        |
| time/              |           |
|    episodes        | 936       |
|    fps             | 68        |
|    time_elapsed    | 13739     |
|    total_timesteps | 936000    |
| train/             |           |
|    actor_loss      | -1.23e+03 |
|    critic_loss     | 1.41      |
|    learning_rate   | 0.001     |
|    n_updates       | 925999    |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 13.8      |
| time/              |           |
|    episodes        | 940       |
|    fps             | 68        |
|    time_elapsed    | 13791     |
|    total_timesteps | 940000    |
| train/             |           |
|    actor_loss      | -1.27e+03 |
|    critic_loss     | 1.39      |
|    learning_rate   | 0.001     |
|    n_updates       | 929999    |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 13.9      |
| time/              |           |
|    episodes        | 944       |
|    fps             | 68        |
|    time_elapsed    | 13842     |
|    total_timesteps | 944000    |
| train/             |           |
|    actor_loss      | -1.27e+03 |
|    critic_loss     | 0.942     |
|    learning_rate   | 0.001     |
|    n_updates       | 933999    |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 15.2      |
| time/              |           |
|    episodes        | 948       |
|    fps             | 68        |
|    time_elapsed    | 13894     |
|    total_timesteps | 948000    |
| train/             |           |
|    actor_loss      | -1.31e+03 |
|    critic_loss     | 2.97      |
|    learning_rate   | 0.001     |
|    n_updates       | 937999    |
----------------------------------
Eval num_timesteps=950000, episode_reward=43.11 +/- 3.01
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 43.1     |
| time/              |          |
|    total_timesteps | 950000   |
| train/             |          |
|    actor_loss      | -1.3e+03 |
|    critic_loss     | 3.29     |
|    learning_rate   | 0.001    |
|    n_updates       | 939999   |
---------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 14.9      |
| time/              |           |
|    episodes        | 952       |
|    fps             | 68        |
|    time_elapsed    | 13947     |
|    total_timesteps | 952000    |
| train/             |           |
|    actor_loss      | -1.29e+03 |
|    critic_loss     | 2.99      |
|    learning_rate   | 0.001     |
|    n_updates       | 941999    |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 15.4      |
| time/              |           |
|    episodes        | 956       |
|    fps             | 68        |
|    time_elapsed    | 13997     |
|    total_timesteps | 956000    |
| train/             |           |
|    actor_loss      | -1.32e+03 |
|    critic_loss     | 3.04      |
|    learning_rate   | 0.001     |
|    n_updates       | 945999    |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 16.4      |
| time/              |           |
|    episodes        | 960       |
|    fps             | 68        |
|    time_elapsed    | 14047     |
|    total_timesteps | 960000    |
| train/             |           |
|    actor_loss      | -1.31e+03 |
|    critic_loss     | 2.73      |
|    learning_rate   | 0.001     |
|    n_updates       | 949999    |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 16.9      |
| time/              |           |
|    episodes        | 964       |
|    fps             | 68        |
|    time_elapsed    | 14099     |
|    total_timesteps | 964000    |
| train/             |           |
|    actor_loss      | -1.29e+03 |
|    critic_loss     | 0.818     |
|    learning_rate   | 0.001     |
|    n_updates       | 953999    |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 17.5      |
| time/              |           |
|    episodes        | 968       |
|    fps             | 68        |
|    time_elapsed    | 14152     |
|    total_timesteps | 968000    |
| train/             |           |
|    actor_loss      | -1.29e+03 |
|    critic_loss     | 5.4       |
|    learning_rate   | 0.001     |
|    n_updates       | 957999    |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 17.9      |
| time/              |           |
|    episodes        | 972       |
|    fps             | 68        |
|    time_elapsed    | 14204     |
|    total_timesteps | 972000    |
| train/             |           |
|    actor_loss      | -1.33e+03 |
|    critic_loss     | 1.2       |
|    learning_rate   | 0.001     |
|    n_updates       | 961999    |
----------------------------------
Eval num_timesteps=975000, episode_reward=31.26 +/- 2.73
Episode length: 1000.00 +/- 0.00
---------------------------------
| eval/              |          |
|    mean_ep_length  | 1e+03    |
|    mean_reward     | 31.3     |
| time/              |          |
|    total_timesteps | 975000   |
| train/             |          |
|    actor_loss      | -1.3e+03 |
|    critic_loss     | 2.3      |
|    learning_rate   | 0.001    |
|    n_updates       | 964999   |
---------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 18.8      |
| time/              |           |
|    episodes        | 976       |
|    fps             | 68        |
|    time_elapsed    | 14259     |
|    total_timesteps | 976000    |
| train/             |           |
|    actor_loss      | -1.32e+03 |
|    critic_loss     | 2.74      |
|    learning_rate   | 0.001     |
|    n_updates       | 965999    |
----------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 19.8     |
| time/              |          |
|    episodes        | 980      |
|    fps             | 68       |
|    time_elapsed    | 14315    |
|    total_timesteps | 980000   |
| train/             |          |
|    actor_loss      | -1.3e+03 |
|    critic_loss     | 3.9      |
|    learning_rate   | 0.001    |
|    n_updates       | 969999   |
---------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 20.4      |
| time/              |           |
|    episodes        | 984       |
|    fps             | 68        |
|    time_elapsed    | 14369     |
|    total_timesteps | 984000    |
| train/             |           |
|    actor_loss      | -1.37e+03 |
|    critic_loss     | 1.44      |
|    learning_rate   | 0.001     |
|    n_updates       | 973999    |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 21.8      |
| time/              |           |
|    episodes        | 988       |
|    fps             | 68        |
|    time_elapsed    | 14424     |
|    total_timesteps | 988000    |
| train/             |           |
|    actor_loss      | -1.34e+03 |
|    critic_loss     | 1.26      |
|    learning_rate   | 0.001     |
|    n_updates       | 977999    |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 23.1      |
| time/              |           |
|    episodes        | 992       |
|    fps             | 68        |
|    time_elapsed    | 14487     |
|    total_timesteps | 992000    |
| train/             |           |
|    actor_loss      | -1.34e+03 |
|    critic_loss     | 2.07      |
|    learning_rate   | 0.001     |
|    n_updates       | 981999    |
----------------------------------
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | 24.1      |
| time/              |           |
|    episodes        | 996       |
|    fps             | 68        |
|    time_elapsed    | 14548     |
|    total_timesteps | 996000    |
| train/             |           |
|    actor_loss      | -1.36e+03 |
|    critic_loss     | 1.01      |
|    learning_rate   | 0.001     |
|    n_updates       | 985999    |
----------------------------------
Eval num_timesteps=1000000, episode_reward=39.76 +/- 2.06
Episode length: 1000.00 +/- 0.00
----------------------------------
| eval/              |           |
|    mean_ep_length  | 1e+03     |
|    mean_reward     | 39.8      |
| time/              |           |
|    total_timesteps | 1000000   |
| train/             |           |
|    actor_loss      | -1.37e+03 |
|    critic_loss     | 0.849     |
|    learning_rate   | 0.001     |
|    n_updates       | 989999    |
----------------------------------
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 1e+03    |
|    ep_rew_mean     | 25       |
| time/              |          |
|    episodes        | 1000     |
|    fps             | 68       |
|    time_elapsed    | 14610    |
|    total_timesteps | 1000000  |
---------------------------------
Saving to logs/td3/Swimmer-v3_1